{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# verileri hazır hale getirme\n",
    "training_dir=\"D:\\yapay zeka projeler/computer_vision/fire_detection/dataset/Training\"\n",
    "validation_dir=\"D:\\yapay zeka projeler/computer_vision/fire_detection/dataset/Validation\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input_shape=(224,224,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 980 images belonging to 2 classes.\n",
      "Found 239 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Veri arttırma Tekniklerii uygulama\n",
    "training_data_generator=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,rotation_range=45,height_shift_range=0.2,width_shift_range=0.2,fill_mode=\"nearest\")\n",
    "\n",
    "validation_data_generator=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# ilgili directory ye gidip dataları çoğaltma\n",
    "train_generator=training_data_generator.flow_from_directory(training_dir,target_size=(224,224),class_mode=\"categorical\",batch_size=64)\n",
    "validation_generator=validation_data_generator.flow_from_directory(validation_dir,target_size=(224,224),class_mode=\"categorical\",batch_size=16)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def fireNet(input_shape):\n",
    "# Model Oluşturduğumuz fonksiyon\n",
    "    model = Sequential(\n",
    "        [\n",
    "            layers.Conv2D(96,(11,11),strides=(4,4),activation=\"relu\",input_shape=input_shape),\n",
    "            layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)) ,\n",
    "\n",
    "            layers.Conv2D(256,(5,5),activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)) ,\n",
    "\n",
    "            layers.Conv2D(512,(5,5),activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)) ,\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.3),\n",
    "\n",
    "            layers.Dense(2048,activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "\n",
    "            layers.Dense(1024,activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "\n",
    "            layers.Dense(2,activation=\"softmax\")\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=Adam(learning_rate=1e-4), metrics=[\"acc\"])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 26, 26, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 22, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 512)         3277312   \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,223,490\n",
      "Trainable params: 10,223,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=fireNet(input_shape)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 79s 5s/step - loss: 0.5597 - acc: 0.6867 - val_loss: 0.4355 - val_acc: 0.7197\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 59s 4s/step - loss: 0.3728 - acc: 0.8210 - val_loss: 0.3351 - val_acc: 0.9038\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 55s 4s/step - loss: 0.2878 - acc: 0.8788 - val_loss: 0.2430 - val_acc: 0.9163\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 55s 4s/step - loss: 0.2729 - acc: 0.8919 - val_loss: 0.2291 - val_acc: 0.9247\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 53s 4s/step - loss: 0.2366 - acc: 0.9203 - val_loss: 0.2195 - val_acc: 0.9372\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 58s 4s/step - loss: 0.2311 - acc: 0.9061 - val_loss: 0.2078 - val_acc: 0.9331\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 54s 4s/step - loss: 0.2244 - acc: 0.9192 - val_loss: 0.1925 - val_acc: 0.9414\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 55s 4s/step - loss: 0.2173 - acc: 0.9203 - val_loss: 0.1962 - val_acc: 0.9331\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 57s 4s/step - loss: 0.1981 - acc: 0.9323 - val_loss: 0.2022 - val_acc: 0.9372\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 57s 4s/step - loss: 0.1937 - acc: 0.9269 - val_loss: 0.1859 - val_acc: 0.9372\n"
     ]
    }
   ],
   "source": [
    "# Eğitim - Fitting\n",
    "\n",
    "history =model.fit(train_generator, steps_per_epoch=15 , epochs=10,validation_data=validation_generator,validation_steps=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-837b7c57a120>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0macc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"acc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mval_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"val_acc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"loss\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Görselleştirme\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs=range(0,50)\n",
    "\n",
    "plt.plot(epochs,acc,\"g\",label=\"Training Accuracy\")\n",
    "plt.plot(epochs,val_acc,\"r\",label=\"Validation Accuracy\")\n",
    "plt.title(\"Training | Validation Accuracy\")\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs,loss,\"blue\",label=\"Training Loss\")\n",
    "plt.plot(epochs,val_loss,\"brown\",label=\"Validation Loss\")\n",
    "plt.title(\"Training | Validation Loss\")\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "#model.save(\"D:\\yapay zeka projeler/computer_vision/fire_detection/models/fire_detection_model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Prediction Images\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import  load_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model=load_model(\"models/fire_detection_model.h5\")\n",
    "path =\"test/test.jpg\"\n",
    "video_path =\"test/test3.mp4\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_img=cv2.imread(path)\n",
    "#Resmi arraya dönüştürüp yeniden boyutlandırma işlemine tabi tuttuk\n",
    "img=np.asarray(test_img)\n",
    "img=cv2.resize(img,(224,224))\n",
    "# normalizasyon işlemi - yani 0-1 arasına sıkıştırdık\n",
    "img=img/255\n",
    "print(img.shape)\n",
    "\n",
    "# görüntüyü 4 boyuta çevirmem lazım\n",
    "img=img.reshape(1,224,224,3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Prediction(Image)\n",
    "\n",
    "predictions=model.predict(img)\n",
    "pred=np.argmax(predictions[0])\n",
    "\n",
    "probability = predictions[0][pred]\n",
    "probability_=\"% {:.2f}\".format(probability*100)\n",
    "\n",
    "if pred==1:\n",
    "    label=\"Yangin Var\"\n",
    "else:\n",
    "    label=\"Normal\"\n",
    "\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "color=(0,255,0)\n",
    "cv2.putText(test_img,label,(35,60),font,1,color,2)\n",
    "cv2.putText(test_img,probability_,(20,100),font,1,color,2)\n",
    "\n",
    "cv2.imshow(\"Prediction : \",test_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected cv::UMat for argument 'src'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-57d1b2d3bff7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mret\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m224\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m224\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;31m# normalizasyon işlemi - yani 0-1 arasına sıkıştırdık\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimg\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m255\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Expected cv::UMat for argument 'src'"
     ]
    }
   ],
   "source": [
    "# Predict (Video)\n",
    "cap=cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    img = np.asarray(frame)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "# normalizasyon işlemi - yani 0-1 arasına sıkıştırdık\n",
    "    img = img / 255\n",
    "    #print(img.shape)\n",
    "\n",
    "# görüntüyü 4 boyuta çevirmem lazım\n",
    "    img = img.reshape(1, 224, 224, 3)\n",
    "\n",
    "# Prediction(Image)\n",
    "\n",
    "    predictions = model.predict(img)\n",
    "    pred = np.argmax(predictions[0])\n",
    "\n",
    "    probability = predictions[0][pred]\n",
    "    probability_ = \"% {:.2f}\".format(probability * 100)\n",
    "\n",
    "    if pred == 1:\n",
    "        label = \"Yangin Var\"\n",
    "    else:\n",
    "        label = \"Normal\"\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    color = (0, 255, 0)\n",
    "    cv2.putText(frame, label, (35, 60), font, 1, color, 2)\n",
    "    cv2.putText(frame, probability_, (20, 100), font, 1, color, 2)\n",
    "\n",
    "    cv2.imshow(\"Prediction : \", frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF==ord(\"q\"):\n",
    "        break\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}